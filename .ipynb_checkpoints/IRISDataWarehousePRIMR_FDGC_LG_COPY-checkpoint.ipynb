{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "# pyodbc is an open source Python module that makes accessing ODBC databases simple\n",
    "import pandas as pd\n",
    "# pandas is a Python package/module(?) that provides fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive\n",
    "# pandas is an open source data analysis library built on top of the Python programming language\n",
    "# The as pd portion of the code then tells Python to give pandas the alias of pd. This allows you to use pandas functions by simply typing pd.function_name rather than pandas.function_name.\n",
    "import getpass\n",
    "# password input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify database connection parameters\n",
    "server = \"ifw9ecos-bvdb11.fws.doi.net\\ecos_beta\"\n",
    "database = \"IRIS_DataWarehouse\"\n",
    "\n",
    "# Uncomment if not using Windows authentication\n",
    "username = input()\n",
    "# The input() function allows user input. Program flow will be stopped until the user has given an input\n",
    "password = getpass.getpass()\n",
    "# The getpass() function of getpass prompts the user to enter a password. By default the keys entered by user in the terminal are not echoed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------\n",
    "# Create a database connection object using a Data Source Name (DSN)\n",
    "# defined by the Windows ODBC Data Source Administrator\n",
    "##----------------------------------------------------\n",
    "#dsn_name = \"\"\n",
    "#db_connection = pyodbc.connect(\"DSN=\"+dsn_name+\";UID=\"+username+\";PWD=\"+password)\n",
    "\n",
    "##----------------------------------------------------\n",
    "#  Create a database connection object by specifying connection parameters\n",
    "##----------------------------------------------------\n",
    "\n",
    "# Uncomment if not using Windows authentication\n",
    "db_connection = pyodbc.connect(\"\\\n",
    "    DRIVER={SQL Server};\\\n",
    "    SERVER=\" + server + \";\\\n",
    "    PORT=1443;\\\n",
    "    DATABASE=\" + database + \";\\\n",
    "    UID=\" + username + \";\\\n",
    "    PWD=\" + password)\n",
    "\n",
    "# connect Python to SQL Server\n",
    "# connect Python to SQL Server\n",
    "# connecting to SQL using pyodbc, use connect\n",
    "# The PYODBC connection string, if connecting outside of the network the SQL Server is on, requires a port number. Simply add 'PORT=1433\n",
    "# https://datatofish.com/how-to-connect-python-to-sql-server-using-pyodbc/\n",
    "\n",
    "#db_connection = pyodbc.connect(\"\\\n",
    "#    DRIVER={SQL Server};\\\n",
    "#    SERVER=\" + server + \";\\\n",
    "#    PORT=1443;\\\n",
    "#    DATABASE=\" + database + \";\\\n",
    "#    Trusted_Connection=yes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db_connection.cursor()\n",
    "#The cursor object allows us to execute queries and retrieve rows. The cursor object is an instance of MySQLCursor class.\n",
    "#A cursor is an object which helps to execute the query and fetch the records from the database.\n",
    "#Cursors are simply objects used for executing SQL commands and retrieving the results.\n",
    "\n",
    "#Python is an object-oriented programming language. Everything is in Python treated as an object, including variable, function, list, tuple, dictionary, set, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create mapper df*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check wd\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "#read in the \"mapper file\" * this only includes fields with a one-to-one relationship \n",
    "mapper = pd.read_csv('one_to_one.csv', header=0)\n",
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO: iterate through all variables in the source_fields list below (aka loop through all fields in the \"source column\")\n",
    "source_fields = mapper['Source'].tolist()\n",
    "\n",
    "variable = source_fields[0]\n",
    "\n",
    "mapper_select = mapper.query('Source == @variable')\n",
    "mapper_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapper_select.loc[0, \"Path\"]\n",
    "#mapper_select.loc[0, \"Node\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Create Queries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMRsurveyID = 'FF01RORG00-072'\n",
    "#print(PRIMRsurveyID)\n",
    "\n",
    "queryIdentification = \"SELECT [\" + variable + \"] FROM [IRIS_DataWarehouse].[Refuges].[VW_Surveys] WHERE [SurveyCode] = '\" + PRIMRsurveyID + \"';\"\n",
    "dfIdentification = pd.read_sql(queryIdentification, db_connection)\n",
    "dfIdentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdwizard.core.xml_utils import XMLRecord, XMLNode #import in this manner requires adding a path file to your site-packages directory\n",
    "# import nodes\n",
    "\n",
    "test = \"C:/Users/lgoetze/scripting/Git/Git/PRIMR_to_FGDC/PRIMR_Metadata_Template_20220429.xml\"\n",
    "#set WD to metadata template\n",
    "template_md = XMLRecord(test)\n",
    "#load XML\n",
    "#template_md \n",
    "# view XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_md.metadata.idinfo.citation.citeinfo.title.text = dfIdentification.loc[0,variable]\n",
    "template_md.metadata.idinfo.citation.citeinfo.lworkcit.citeinfo = dfIdentification.loc[0,variable]\n",
    "## WORK ON THIS. How to pull path from \"\"template_md.\" + mapper_select.loc[0, \"Path\"]\"\n",
    "#template_md\n",
    "\n",
    "#template_md.metadata.search_xpath(\"idinfo/citation/citeinfo/title\")\n",
    "#template_md.metadata.idinfo.citation.citeinfo.lworkcit.citeinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"template_md\"\n",
    "path\n",
    "locals()[path]\n",
    "\n",
    "#path2 =\"template_md.\" + mapper_select.loc[0, \"Path\"]\n",
    "#path2\n",
    "#locals()[path2]\n",
    "\n",
    "\n",
    "#locals()[path].metadata.idinfo\n",
    "\n",
    "## STUCK HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "from lxml import etree as et\n",
    "\n",
    "def createXMLNode(df, element_tag):\n",
    "    \n",
    "    element = et.Element(element_tag)\n",
    "    element.text = dfIdentification.loc[0,variable]\n",
    "      \n",
    "    \n",
    "    return(XMLNode(et.tostring(element, pretty_print=True).decode('utf-8')))\n",
    "\n",
    "new_node = createXMLNode(dfIdentification, mapper_select.loc[0, \"Node\"])\n",
    "new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = template_md.metadata.idinfo.citation.citeinfo\n",
    "#node = template_md.metadata.idinfo.citation.citeinfo.lworkcit.citeinfo\n",
    "node.replace_child(new_node)\n",
    "node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRATCH BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = mapper_select.loc[0, \"Path\"]\n",
    "final = str(\"template_md.\" + path)\n",
    "kw = locals()[final]\n",
    "kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \".metadata.idinfo.citation.citeinfo.title.text\"\n",
    "\n",
    "#locals()[\" + test + \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template_md.metadata.idinfo.citation.citeinfo.title.text = dfIdentification.at[0, one_1.iloc[0, 0]]\n",
    "\n",
    "dfIdentification.loc[0,variable]\n",
    "#template_md.metadata.idinfo.citation.citeinfo.title.text = dfIdentification[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"metadata.idinfo\"\n",
    "# print(f\"{x}\")\n",
    "x\n",
    "\n",
    "text_01 = \"\"\"print('.metadata')\"\"\"\n",
    "#exec(text_01)\n",
    "\n",
    "locals()[\"template_md\"].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_md.metadata.idinfo.citation.citeinfo.title.text = dfIdentification.at[0,'SurveyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "getattr(template_md, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(template_md, metadata.idinfo.citation.citeinfo.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = dfIdentification.at[0,'SurveyName']\n",
    "template_md\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = dfIdentification.at[0,one.iloc[0, 0]]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"template_md.\" + one.iloc[0, 2]\n",
    "locals()['path'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_md?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"template_md.\" + one.iloc[0, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"template_md.\" + one.iloc[0, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"template_md.\" + one.iloc[0, 2] = dfIdentification.at[0,one.iloc[0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryIdentification = \"SELECT [SurveyCode],[Station],[SurveyName], [SurveyType],[ResourceThemeLevel1],[ResourceThemeLevel2] ,[AnswerQ1],[AnswerQ2],[AnswerQ3],[AnswerQ4],[SurveyCoordinatorName],[SurveyCoordinatorTitle],[StationName],[SurveyArea],[ManagementUnits] FROM [IRIS_DataWarehouse].[Refuges].[VW_Surveys] WHERE [SurveyCode] = '\" + PRIMRsurveyID + \"';\"\n",
    "dfIdentification = pd.read_sql(queryIdentification, db_connection)\n",
    "dfIdentification\n",
    "\n",
    "#creates a pandas df?\n",
    "#Pandas read_sql() method allows you to run any SQL queries from the database\n",
    "#pandas.read_sql(sql, con, index_col=None)\n",
    "#sql: It is a SQL query you want to perform on the database.\n",
    "#con: Database connection.\n",
    "#https://www.datasciencelearner.com/pandas-read_sql-implementation-examples/#:~:text=Steps%20to%20implement%20Pandas%20read_sql%20%28%29%20method%201,5%20Implement%20the%20pandas%20read_sql%20%28%29%20method.%20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryKeywords = \"SELECT Refuges.DimKeyword.Name as theme FROM Refuges.DimKeyword RIGHT OUTER JOIN Refuges.DimSurvey INNER JOIN Refuges.FactSurveys ON Refuges.DimSurvey.ID = Refuges.FactSurveys.SurveyID INNER JOIN Refuges.FactSurveyKeywords ON Refuges.FactSurveys.SurveyID = Refuges.FactSurveyKeywords.SurveyID ON Refuges.DimKeyword.ID = Refuges.FactSurveyKeywords.KeywordID WHERE Refuges.DimSurvey.SurveyCode = '\" + PRIMRsurveyID + \"';\"\n",
    "# query\n",
    "dfKeywords = pd.read_sql(queryKeywords, db_connection)\n",
    "# creates a dataframe\n",
    "#pandas.read_sql reads SQL query or database table into a DataFrame\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html\n",
    "# pd.read_sql(sql, con)\n",
    "# sql = SQL query to be executed \n",
    "# con = SQLAlchemy connectable, str, or sqlite3 connection\n",
    "dfKeywords\n",
    "#dfKeywords.to_csv(\"keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querySurveyCoordinator = \"SELECT Refuges.DimSurvey.SurveyCode, Refuges.DimSurvey.SurveyCoordinatorName, DimStaff.Title, DimStaff.OrganizationCode, DimStaff.City, DimStaff.StateCode, DimStaff.ZipCode, DimStaff.PhoneNumber, DimStaff.CellNumber, DimStaff.Email, DimStaff.Office, DimStaff.Department, DimOrganization.OrgCode FROM FactStaff INNER JOIN DimStaff ON FactStaff.StaffID = DimStaff.ID AND FactStaff.StaffID = DimStaff.ID AND FactStaff.StaffID = DimStaff.ID INNER JOIN DimOrganization ON FactStaff.OrganizationID = DimOrganization.ID AND FactStaff.OrganizationID = DimOrganization.ID AND FactStaff.OrganizationID = DimOrganization.ID RIGHT OUTER JOIN Refuges.DimSurvey ON DimStaff.FullName = Refuges.DimSurvey.SurveyCoordinatorName WHERE Refuges.DimSurvey.SurveyCode = '\" + PRIMRsurveyID + \"';\"\n",
    "#create query\n",
    "dfSurveyCoordinator = pd.read_sql(querySurveyCoordinator, db_connection)\n",
    "# create a dataframe. pandas.read_sql reads SQL query into a DataFrame\n",
    "dfSurveyCoordinator\n",
    "# view dataframe\n",
    "# dfSurveyCoordinator.to_csv(\"surveycoordinator.csv\")\n",
    "# save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryBioticGroup = \"SELECT Refuges.DimSurvey.SurveyCode, Refuges.DimBioticGroup.ITIS_TSN, Refuges.DimBioticGroup.ITIS_TSN_Parent, Refuges.DimBioticGroup.ScientificName_Parent, Refuges.DimBioticGroup.CommonName_Parent,     Refuges.DimBioticGroup.Rank_Parent FROM Refuges.FactSurveyBioticGroups INNER JOIN Refuges.DimSurvey ON Refuges.FactSurveyBioticGroups.SurveyID = Refuges.DimSurvey.ID INNER JOIN Refuges.DimBioticGroup ON Refuges.FactSurveyBioticGroups.BioticGroupID = Refuges.DimBioticGroup.ID WHERE Refuges.DimSurvey.SurveyCode = '\" + PRIMRsurveyID + \"';\"\n",
    "dfBioticGroup = pd.read_sql(queryBioticGroup, db_connection)\n",
    "dfBioticGroup\n",
    "#dfBioticGroup.to_csv(\"bioticgroup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Working with metadata XML*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdwizard.core.xml_utils import XMLRecord, XMLNode #import in this manner requires adding a path file to your site-packages directory\n",
    "# import nodes\n",
    "\n",
    "test = \"C:/Users/lgoetze/scripting/Git/Git/PRIMR_to_FGDC/PRIMR_Metadata_Template_20220429.xml\"\n",
    "#set WD to metadata template\n",
    "original_md = XMLRecord(test)\n",
    "#load XML\n",
    "original_md \n",
    "# view XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-to-one is easy\n",
    "# edit individual node text\n",
    "original_md.metadata.idinfo.citation.citeinfo.title.text = dfIdentification.at[0,'SurveyName']\n",
    "# set title 'text' node in XML to \"survey name\" value in 0 row (first row) of dfIdentification pandas dataframe\n",
    "original_md.metadata.idinfo.ptcontac.cntinfo.cntorgp.cntper.text = dfSurveyCoordinator.at[0,'SurveyCoordinatorName']\n",
    "original_md.metadata.idinfo.ptcontac.cntinfo.cntpos.text = dfSurveyCoordinator.at[0,'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gather keywords from a variety of queries and append into one dataframe\n",
    "dfKeywordsSet = (\n",
    "    pd.DataFrame(dfIdentification)\n",
    "    .loc[:, ['ResourceThemeLevel1', 'ResourceThemeLevel2', 'SurveyType', 'SurveyCode']]\n",
    "    .melt()\n",
    "#melt () function is used to unpivot a given DataFrame from wide format to long format\n",
    "    .drop(columns=['variable'])\n",
    "# remove the 'variable' columns because the values will all fall under a 'theme' column\n",
    "    .rename(columns={'value':'theme'})\n",
    "# rename column\n",
    "    .append(dfKeywords)\n",
    "# append keywords from the 'dfkeywords' dataframe\n",
    "    .append((\n",
    "        pd.DataFrame(dfBioticGroup)\n",
    "        .loc[:, ['ScientificName_Parent']]\n",
    "        .melt()\n",
    "        .drop(columns=['variable'])\n",
    "        .rename(columns={'value':'theme'})),\n",
    "        ignore_index=True\n",
    "    )\n",
    "# append 'dfBioticGroup'\n",
    ")\n",
    "dfKeywordsSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKeywordsSet.iloc[0][0]\n",
    "#call cell values from \"dfKeywordsSet\" df (0 row, 0 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = original_md.metadata.idinfo.keywords\n",
    "#assign kw to node of intereset (keyword)\n",
    "kw.clear_children('theme')\n",
    "#clear theme node\n",
    "kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Leana testing how to create xml using lxml*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfKeywordsSet.columns.format()\n",
    "#dfKeywordsSet.index.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "# root = etree.XML('<root><a><b/></a></root>')\n",
    "# etree.tostring(root)\n",
    "# print(etree.tostring(root, xml_declaration=True))\n",
    "# print(etree.tostring(root, encoding='iso-8859-1'))\n",
    "# print(etree.tostring(root, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# root = etree.Element('theme')\n",
    "# etree.SubElement(root, 'themekt').text = 'themekt_test'\n",
    "# etree.SubElement(root, 'themekey').text = 'themekey_test'\n",
    "# # Be mindful when adding assigning variables after\n",
    "# # the .text on SubElement call, as it will return \n",
    "# # the text and not the Element\n",
    "# #etree.SubElement(inventory, 'themekt', {'count': '5'}).text = 'Golden Delicious'\n",
    "# #employees = etree.SubElement(store, 'themekey')\n",
    "# #etree.SubElement(employees, 'SearingFrost', {'title': 'writer'})\n",
    "\n",
    "# XMLNode(etree.tostring(root, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lxml\n",
    "from lxml import etree as et\n",
    "\n",
    "def createXMLNode_from_df_LG(df, element_tag, subelement_tag, optional_subelement_tag, optional_subelement_text):\n",
    "    \n",
    "    element = et.Element(element_tag)\n",
    "    et.SubElement(element, optional_subelement_tag).text = optional_subelement_text\n",
    "# if there are ever more than one <optional_subelement_tag> than we should add it to the loop below\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        subelement = et.SubElement(element, subelement_tag)\n",
    "        subelement.text = str(row[1][0])\n",
    "\n",
    "    return(XMLNode(et.tostring(element, pretty_print=True).decode('utf-8')))\n",
    "\n",
    "new_node = createXMLNode_from_df_LG(dfKeywordsSet, \"theme\", \"themekey\", \"themkt\", \"Add 'themeky' text here\")\n",
    "\n",
    "# Resource: https://stackoverflow.com/questions/49439008/creating-an-xml-file-from-a-dataframe-using-python-and-lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kw.add_child(new_node)\n",
    "kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_md.save(fname='PRIMR_Metadata_Template_20220429Testing_lg.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Khem's code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXMLNode_from_df(df, subelement_tag, optional_element_tag):\n",
    "# “def” is short for the word “define” and it is used to signify the beginning of a function definition in Python\n",
    "# createXMLNode_from_df() is the function\n",
    "# specify df, subelement tag, and optional element tag\n",
    "    xml_data = ['<root>']\n",
    "# create starting point\n",
    "    for column in df.columns:\n",
    "        xml_data.append('<{}>'.format(column))# Opening element tag\n",
    "# adds the \"theme\" node\"\n",
    "        xml_data.append(optional_element_tag.format(column))\n",
    "# adds the \"themekt\" node\n",
    "        for field in df.index:\n",
    "# for every row in df.index\n",
    "# writing sub-elements\n",
    "            xml_data.append('<temp_tag>{1}</temp_tag>'.format(field, df[column][field]))\n",
    "# append creating <temp_tag>\n",
    "        xml_data.append('</{}>'.format(column))  # Closing element tag\n",
    "# close theme\n",
    "    xml_data.append('</root>')\n",
    "# close root\n",
    "\n",
    "    my_string = \"\"\n",
    "    for i in xml_data:\n",
    "        my_string += ('{}').format(i)\n",
    "\n",
    "    new_string = (\n",
    "        my_string\n",
    "            .replace('<root>','')\n",
    "            .replace('</root>','')\n",
    "        # remove root node\n",
    "            .replace('temp_tag',subelement_tag)\n",
    "        # replace <temp_tag> with <themekey>\n",
    "    )\n",
    "    return(XMLNode(new_string))\n",
    "\n",
    "newKW = createXMLNode_from_df(dfKeywordsSet, \"themekey\", \"<themekt>FWS-PRIMR</themekt>\")\n",
    "newKW\n",
    "\n",
    "\n",
    "# lxml generate xml from table\n",
    "# parse and create xml\n",
    "# for this node in the metadata\n",
    "# run ad hoc query and import into access database- database has all relatinships set up\n",
    "# store mapping in a dataframe\n",
    "# if we provide the mapping then create a generic functions that you can call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = original_md.metadata.idinfo.keywords\n",
    "#assign kw to node of intereset (keyword)\n",
    "kw.clear_children('theme')\n",
    "kw.add_child(newKW)\n",
    "kw\n",
    "# add child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to new xml\n",
    "original_md.save(fname='PRIMR_Metadata_Template_20220429Testing.xml')\n",
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
